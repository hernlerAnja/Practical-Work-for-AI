{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation & Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from Bio.PDB import PDBParser\n",
    "import torchmetrics\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add tankbind directory to System path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbind_src_folder_path = \"./tankbind/\"\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from tankbind\n",
    "from feature_utils import get_protein_feature, get_clean_res_list, extract_torchdrug_feature_from_mol, get_canonical_smiles\n",
    "from utils import construct_data_from_graph_gvp, evaulate_with_affinity, evaulate\n",
    "from model import get_model\n",
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "from metrics import print_metrics, myMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"dataset_10\"\n",
    "df = pd.read_csv(f'{dataset_path}/Mcule_10000.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the protein names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_protein_names(file_path):\n",
    "    protein_names = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Get the base name without directory path\n",
    "            base_name = os.path.basename(line.strip())\n",
    "            # Split the base name to get the protein name without extension\n",
    "            protein_name = os.path.splitext(base_name)[0]\n",
    "            protein_names.append(protein_name)\n",
    "    return protein_names\n",
    "\n",
    "file_path = 'pdb_dataset.ds'\n",
    "protein_names = extract_protein_names(file_path)\n",
    "\n",
    "# print(protein_names[0:5]. len(protein_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select 1/10 of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(protein_names) * 0.1\n",
    "sampled_protein_names = random.sample(protein_names, n)\n",
    "\n",
    "# print(sampled_protein_names[0:5], len(sampled_protein_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get protein features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_proteins(protein_names, pdb_directory):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    protein_dict = {}\n",
    "\n",
    "    for proteinName in protein_names:\n",
    "        try:\n",
    "            proteinFile = f\"{pdb_directory}/{proteinName}.pdb\"\n",
    "            s = parser.get_structure(proteinName, proteinFile)\n",
    "            res_list = list(s.get_residues())\n",
    "            clean_res_list = get_clean_res_list(res_list, ensure_ca_exist=True)\n",
    "            protein_dict[proteinName] = get_protein_feature(clean_res_list)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {proteinName}: {e}\")\n",
    "\n",
    "    return protein_dict\n",
    "\n",
    "pdb_directory = \"PDB_files\"  # Directory containing PDB files\n",
    "\n",
    "protein_dict = process_proteins(sampled_protein_names, pdb_directory)\n",
    "\n",
    "# torch.save(protein_dict, 'protein_dict.pt')   # execute only in first notebook run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_names_new = list(protein_dict.keys())  # updated protein names after processing, in case some proteins failed to process\n",
    "\n",
    "# print(len(protein_names_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create protein dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "for protein_name in protein_names_new:\n",
    "    for i, line in tqdm(df.iterrows(), total=len(df)):\n",
    "        smiles = line['smiles']\n",
    "        compund_name = ''\n",
    "        protein_name = protein_name\n",
    "        com = \",\".join([str(x.round(3)) for x in protein_dict[protein_name][0].mean(axis=0).numpy()])\n",
    "        info.append([protein_name, compund_name, smiles, \"protein_center\", com])\n",
    "\n",
    "info = pd.DataFrame(info, columns=['protein_name', 'compound_name', 'smiles', 'pocket_name', 'pocket_com'])\n",
    "\n",
    "# torch.save(info, 'data.pt')   # execute only in first notebook run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, molecule_dict=None, proteinMode=0, compoundMode=1,\n",
    "                 pocket_radius=20, shake_nodes=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        self.molecule_dict = molecule_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.molecule_dict = torch.load(self.processed_paths[2])\n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt', 'proteins.pt', 'molecules.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Save data and protein dictionary\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "        torch.save(self.molecule_dict, self.processed_paths[2])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        smiles = line['smiles']\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if isinstance(pocket_com, str) else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line.get('use_whole_protein', False)\n",
    "\n",
    "        protein_name = line['protein_name']\n",
    "        protein_data = self.protein_dict.get(protein_name)\n",
    "        \n",
    "        if protein_data is None:\n",
    "            raise ValueError(f\"Protein {protein_name} not found in pre-calculated protein dictionary\")\n",
    "\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = protein_data\n",
    "\n",
    "        # Load precomputed molecular features\n",
    "        molecule_data = self.molecule_dict.get(smiles)\n",
    "        if molecule_data is None:\n",
    "            raise ValueError(f\"SMILES {smiles} not found in precomputed molecular dictionary\")\n",
    "        \n",
    "        coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = self.molecule_dict[smiles]\n",
    "\n",
    "        data, input_node_list, keepNode = construct_data_from_graph_gvp(\n",
    "            protein_node_xyz, protein_seq, protein_node_s, protein_node_v, \n",
    "            protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "            pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "            use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode\n",
    "        )\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset dirrectory\n",
    "# os.system(f\"rm -r {dataset_path}\") # only on first run\n",
    "# os.system(f\"mkdir -p {dataset_path}\") # only on first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precalculate the molecule_dict s.t. the Dataset creation is no longer dependent on torchdrug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute only in first notebook run\n",
    "smiles_list = info['smiles'].to_list()\n",
    "smiles_set = set(smiles_list)\n",
    "\n",
    "molecule_dict = {}\n",
    "for molecule in smiles_set:\n",
    "    smiles = get_canonical_smiles(molecule)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol.Compute2DCoords()\n",
    "    molecule_dict[molecule] = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)\n",
    "\n",
    "torch.save(molecule_dict, 'dataset_10/processed/molecules.pt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only excute after running the code above once (& only if needed), otherwise FileNotFoundError\n",
    "data = torch.load(f'{dataset_path}/processed/data.pt')\n",
    "protein_dict = torch.load(f'{dataset_path}/processed/proteins.pt')\n",
    "molecule_dict = torch.load(f'{dataset_path}/processed/molecules.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MyDataset_VS(root=dataset_path, data=info, protein_dict=protein_dict, molecule_dict=molecule_dict) # only on first run, otherwise execute line below\n",
    "dataset = MyDataset_VS(root=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # higher batchsize possible only if enough memmory is available (eg.: 10)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = get_model(0, logging, device)\n",
    "\n",
    "# load self-dock model\n",
    "modelFile = \"./model/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=0) # changed num_workers from 8 to 0, due to multiprocessing error\n",
    "affinity_pred_list = []\n",
    "for data in tqdm(data_loader):\n",
    "    if data.dis_map.shape[0] < 50000: # to filter out proteins with dismap size > 10000 -> 50000 due to batch size 5, can be adjusted as needed (if it's too big, it will cause a memory error)\n",
    "        data = data.to(device)\n",
    "        y_pred, affinity_pred = model(data)\n",
    "        affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "    else:\n",
    "        affinity_pred_list.append(torch.zeros(5, 1))\n",
    "\n",
    "affinity_pred_list = torch.cat(affinity_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dataset.data\n",
    "info['affinity'] = affinity_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv(f\"{dataset_path}/result_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose compund with highest affinity score for each protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(f'{dataset_path}/result_info.csv') # only execute if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = info.loc[info.groupby('protein_name',sort=False)['affinity'].agg('idxmax')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = chosen[chosen['affinity'] != 0]\n",
    "chosen_smiles = chosen['smiles'].tolist()\n",
    "\n",
    "chosen_data = MyDataset_VS(root=dataset_path, data=chosen) \n",
    "chosen_data.data = chosen\n",
    "\n",
    "# print(len(chosen_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pocket_name</th>\n",
       "      <th>pocket_com</th>\n",
       "      <th>affinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9658</td>\n",
       "      <td>9658</td>\n",
       "      <td>9658</td>\n",
       "      <td>2R3G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N1(N=CC(C(=O)NCC2=CC=C(C(OC)=C2)OC)=C1COC)C1N=...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>1.924,29.866,21.385</td>\n",
       "      <td>8.819671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15087</td>\n",
       "      <td>15087</td>\n",
       "      <td>15087</td>\n",
       "      <td>1P4O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C(/N1CCC(CC1)(C(N)=O)N1CCCCC1)(\\NC1=NC(C)=CC(C...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>17.63,64.754,17.18</td>\n",
       "      <td>6.751139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29273</td>\n",
       "      <td>29273</td>\n",
       "      <td>29273</td>\n",
       "      <td>8AO3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N12N=C(SC1=NC(=O)C(=CC1C=C(N(C3C=CC(=CC=3)CC)C...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>-0.879,3.457,37.96</td>\n",
       "      <td>9.114771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38556</td>\n",
       "      <td>38556</td>\n",
       "      <td>38556</td>\n",
       "      <td>6W4P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C12(C3C=CC=CC=3C(C3C=CC=CC=3)(C3=CC=CC=C3)N1C1...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>178.04,175.021,180.363</td>\n",
       "      <td>5.292430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44114</td>\n",
       "      <td>44114</td>\n",
       "      <td>44114</td>\n",
       "      <td>3OJM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N1C(C2C=CC(=CC=2)C)=CSC=1NN=CC1C2C=CC=CC=2C=C2...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>3.855,32.326,32.293</td>\n",
       "      <td>6.531941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>816059</td>\n",
       "      <td>476059</td>\n",
       "      <td>816059</td>\n",
       "      <td>5U1M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN(C1SC2C(=CC(=CC=2)Cl)N=1)C(C1(C#N)CCCCC1)=O</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>8.684,19.363,14.771</td>\n",
       "      <td>8.048314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>829833</td>\n",
       "      <td>489833</td>\n",
       "      <td>829833</td>\n",
       "      <td>7UP4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1(C(=O)N2CCC3C(=CC=CC=3)C2)=NN(C2CCC(CC1=2)N1...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>27.132,49.381,62.994</td>\n",
       "      <td>4.963066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>836655</td>\n",
       "      <td>496655</td>\n",
       "      <td>836655</td>\n",
       "      <td>1W7H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N1(CC2=C(C)C=C(C=C2C)C)C=NC2C(=CC3=C(CCC(C)C3)...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>21.934,25.734,41.109</td>\n",
       "      <td>8.003905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>847459</td>\n",
       "      <td>507459</td>\n",
       "      <td>847459</td>\n",
       "      <td>6YPK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N1([C@H]2[C@](C)(O)CCN(C(=O)CCC3N(CC)C4=C(C=CC...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>-106.935,-186.89,310.699</td>\n",
       "      <td>7.838318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>851635</td>\n",
       "      <td>511635</td>\n",
       "      <td>851635</td>\n",
       "      <td>1UU9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N12C(=N)C(=CC3C=C(N(C4C(OC)=CC=C(OC)C=4)C=3C)C...</td>\n",
       "      <td>protein_center</td>\n",
       "      <td>23.757,79.455,17.703</td>\n",
       "      <td>8.534319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Unnamed: 0.1  Unnamed: 0 protein_name  compound_name  \\\n",
       "0     9658          9658        9658         2R3G            NaN   \n",
       "1    15087         15087       15087         1P4O            NaN   \n",
       "2    29273         29273       29273         8AO3            NaN   \n",
       "3    38556         38556       38556         6W4P            NaN   \n",
       "4    44114         44114       44114         3OJM            NaN   \n",
       "..     ...           ...         ...          ...            ...   \n",
       "81  816059        476059      816059         5U1M            NaN   \n",
       "82  829833        489833      829833         7UP4            NaN   \n",
       "83  836655        496655      836655         1W7H            NaN   \n",
       "84  847459        507459      847459         6YPK            NaN   \n",
       "85  851635        511635      851635         1UU9            NaN   \n",
       "\n",
       "                                               smiles     pocket_name  \\\n",
       "0   N1(N=CC(C(=O)NCC2=CC=C(C(OC)=C2)OC)=C1COC)C1N=...  protein_center   \n",
       "1   C(/N1CCC(CC1)(C(N)=O)N1CCCCC1)(\\NC1=NC(C)=CC(C...  protein_center   \n",
       "2   N12N=C(SC1=NC(=O)C(=CC1C=C(N(C3C=CC(=CC=3)CC)C...  protein_center   \n",
       "3   C12(C3C=CC=CC=3C(C3C=CC=CC=3)(C3=CC=CC=C3)N1C1...  protein_center   \n",
       "4   N1C(C2C=CC(=CC=2)C)=CSC=1NN=CC1C2C=CC=CC=2C=C2...  protein_center   \n",
       "..                                                ...             ...   \n",
       "81      CN(C1SC2C(=CC(=CC=2)Cl)N=1)C(C1(C#N)CCCCC1)=O  protein_center   \n",
       "82  C1(C(=O)N2CCC3C(=CC=CC=3)C2)=NN(C2CCC(CC1=2)N1...  protein_center   \n",
       "83  N1(CC2=C(C)C=C(C=C2C)C)C=NC2C(=CC3=C(CCC(C)C3)...  protein_center   \n",
       "84  N1([C@H]2[C@](C)(O)CCN(C(=O)CCC3N(CC)C4=C(C=CC...  protein_center   \n",
       "85  N12C(=N)C(=CC3C=C(N(C4C(OC)=CC=C(OC)C=4)C=3C)C...  protein_center   \n",
       "\n",
       "                  pocket_com  affinity  \n",
       "0        1.924,29.866,21.385  8.819671  \n",
       "1         17.63,64.754,17.18  6.751139  \n",
       "2         -0.879,3.457,37.96  9.114771  \n",
       "3     178.04,175.021,180.363  5.292430  \n",
       "4        3.855,32.326,32.293  6.531941  \n",
       "..                       ...       ...  \n",
       "81       8.684,19.363,14.771  8.048314  \n",
       "82      27.132,49.381,62.994  4.963066  \n",
       "83      21.934,25.734,41.109  8.003905  \n",
       "84  -106.935,-186.89,310.699  7.838318  \n",
       "85      23.757,79.455,17.703  8.534319  \n",
       "\n",
       "[85 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:28:29   5 stack, readout2, pred dis map add self attention and GVP embed, compound model GIN\n"
     ]
    }
   ],
   "source": [
    "# get model if previous code not executed in this notebook\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = get_model(0, logging, device)\n",
    "\n",
    "# load self-dock model\n",
    "modelFile = \"./model/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [08:43<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(chosen_data, batch_size=1, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=0)\n",
    "\n",
    "y_preds = []\n",
    "tankbind_list = []\n",
    "\n",
    "for i, data_with_batch_info in enumerate(tqdm(data_loader)):\n",
    "\n",
    "    y_pred, affinity_pred = model(data_with_batch_info)\n",
    "\n",
    "    coords = data_with_batch_info.coords.to(device)\n",
    "    protein_nodes_xyz = data_with_batch_info.node_xyz.to(device)\n",
    "    n_compound = coords.shape[0] \n",
    "    n_protein = protein_nodes_xyz.shape[0] \n",
    "    y_pred = y_pred.reshape(n_protein, n_compound).to(device).detach()\n",
    "    y_preds.append(y_pred)\n",
    "    y = data_with_batch_info.dis_map.reshape(n_protein, n_compound).to(device)\n",
    "    compound_pair_dis_constraint = torch.cdist(coords, coords)\n",
    "\n",
    "    # Extract SMILES and generate 2D coordinates\n",
    "    smiles = chosen_smiles[i]  \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol.Compute2DCoords()\n",
    "\n",
    "    # Compute LAS distance constraint mask\n",
    "    LAS_distance_constraint_mask = get_LAS_distance_constraint_mask(mol).bool()\n",
    "\n",
    "    # Calculate information\n",
    "    info = get_info_pred_distance(coords, y_pred, protein_nodes_xyz, compound_pair_dis_constraint,\n",
    "                                  LAS_distance_constraint_mask=LAS_distance_constraint_mask,\n",
    "                                  n_repeat=1, show_progress=False)\n",
    "\n",
    "    # Save to file\n",
    "    toFile = f'{dataset_path}/chosen/KIBA_tankbind_{i}.sdf' # instead of i use 'chosen.iloc(i)['protein_name']' as file name\n",
    "    new_coords = info.sort_values(\"loss\")['coords'].iloc[0].astype(np.double)\n",
    "    write_with_new_coords(mol, new_coords, toFile)\n",
    "    \n",
    "    tankbind_list.append([mol, new_coords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'KIBA_tankbind.sdf'\n",
    "\n",
    "# Write each molecule with its new coordinates to a temporary file and append to the final SDF file\n",
    "with open(output_file, 'w') as final_sdf:\n",
    "    for i, (mol, new_coords) in enumerate(tankbind_list):\n",
    "        temp_file = f'temp_{i}.sdf'\n",
    "        write_with_new_coords(mol, new_coords, temp_file)\n",
    "        with open(temp_file, 'r') as temp_sdf:\n",
    "            final_sdf.write(temp_sdf.read())\n",
    "        os.remove(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, criterion, device, saveFileName=None):\n",
    "    y_list = []\n",
    "    y_pred_list = []\n",
    "    batch_loss = 0.0\n",
    "    for data in tqdm(data_loader):\n",
    "        data = data.to(device)\n",
    "        y_pred, _ = model(data)\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(y_pred, data.y)\n",
    "        batch_loss += len(y_pred)*loss.item()\n",
    "        y_list.append(data.y)\n",
    "        y_pred_list.append(y_pred.sigmoid().detach())\n",
    "        # torch.cuda.empty_cache()\n",
    "    y = torch.cat(y_list)\n",
    "    y_pred = torch.cat(y_pred_list)\n",
    "    metrics = {\"loss\":batch_loss/len(y_pred)}\n",
    "    metrics.update(myMetric(y_pred, y))\n",
    "    if saveFileName:\n",
    "        torch.save((y, y_pred), saveFileName)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMetric(y_pred, y, threshold=0.5):\n",
    "    y = y.float()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "    # y = y.long()\n",
    "    y = y.bool()\n",
    "    acc = torchmetrics.functional.accuracy(y_pred, y, task='binary', threshold=threshold)\n",
    "    auroc = torchmetrics.functional.auroc(y_pred, y, task='binary')\n",
    "    precision_0, precision_1 = torchmetrics.functional.precision(y_pred, y, task='multiclass',\n",
    "                                      num_classes=2,\n",
    "                                      average='none', threshold=threshold)\n",
    "    recall_0, recall_1 = torchmetrics.functional.recall(y_pred, y, task='multiclass',\n",
    "                                      num_classes=2,\n",
    "                                      average='none', threshold=threshold)\n",
    "    f1_0, f1_1 = torchmetrics.functional.f1_score(y_pred, y, task='multiclass',\n",
    "                                      num_classes=2,\n",
    "                                      average='none', threshold=threshold)\n",
    "    return {\"BCEloss\":loss.item(),\n",
    "            \"acc\":acc, \"auroc\":auroc, \"precision_1\":precision_1,\n",
    "           \"recall_1\":recall_1, \"f1_1\":f1_1,\"precision_0\":precision_0,\n",
    "           \"recall_0\":recall_0, \"f1_0\":f1_0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [01:52<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:35:19   epoch 0   , test,  loss:95.865, BCEloss: 9.708, acc: 0.006, auroc: 0.629, precision_1: 0.000, recall_1: 0.000, f1_1: 0.000, precision_0: 0.994, recall_0: 1.000, f1_0: 0.997\n"
     ]
    }
   ],
   "source": [
    "saveFileName = f\"{dataset_path}/chosen_metrics.pt\"\n",
    "metrics = evaluate(data_loader, model, torch.nn.MSELoss(), device, saveFileName=saveFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss:95.865, BCEloss: 9.708, acc: 0.006, auroc: 0.629, precision_1: 0.000, recall_1: 0.000, f1_1: 0.000, precision_0: 0.994, recall_0: 1.000, f1_0: 0.997'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
